{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'utilities'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-14a08a558add>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mutilities\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named 'utilities'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.cross_validation import StratifiedKFold, KFold, train_test_split\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential, Model, model_from_json\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers import Merge\n",
    "from keras.layers import LSTM, Input, Lambda\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from utilities.utils import *\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "# %matplotlib inline\n",
    "\n",
    "# from IPython.display import clear_output\n",
    "batch_size = 64\n",
    "nb_feat = 34 # feature 向量的维度\n",
    "nb_class = 4 # 情绪分类数量\n",
    "nb_epoch = 100\n",
    "\n",
    "optimizer = 'Adadelta'\n",
    "\n",
    "params = Constants()\n",
    "params.path_to_data = \"C:\\\\Users\\\\SparcGuys\\\\Desktop\\\\IEMOCAP_full_release\\\\\"\n",
    "\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    # the 2 is critical here since the first couple outputs of the RNN\n",
    "    # tend to be garbage:\n",
    "    shift = 2\n",
    "    y_pred = y_pred[:, shift:, :]\n",
    "    input_length -= shift\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "def build_model(nb_feat, nb_class, optimizer='Adadelta'):\n",
    "    net_input = Input(name=\"the_input\", shape=(78, nb_feat))\n",
    "    forward_lstm1  = LSTM(output_dim=64, \n",
    "                          return_sequences=True, \n",
    "                          activation=\"tanh\"\n",
    "                         )(net_input)\n",
    "    backward_lstm1 = LSTM(output_dim=64, \n",
    "                          return_sequences=True, \n",
    "                          activation=\"tanh\",\n",
    "                          go_backwards=True\n",
    "                         )(net_input)\n",
    "    blstm_output1  = Merge(mode='concat')([forward_lstm1, backward_lstm1])\n",
    "\n",
    "    forward_lstm2  = LSTM(output_dim=64, \n",
    "                          return_sequences=True, \n",
    "                          activation=\"tanh\"\n",
    "                         )(blstm_output1)\n",
    "    backward_lstm2 = LSTM(output_dim=64, \n",
    "                          return_sequences=True, \n",
    "                          activation=\"tanh\",\n",
    "                          go_backwards=True\n",
    "                         )(blstm_output1)\n",
    "    blstm_output2  = Merge(mode='concat')([forward_lstm2, backward_lstm2])\n",
    "\n",
    "    hidden = TimeDistributed(Dense(512, activation='tanh'))(blstm_output2)\n",
    "    output = TimeDistributed(Dense(nb_class + 1, activation='softmax'))(hidden)\n",
    "\n",
    "    labels = Input(name='the_labels', shape=[1], dtype='float32')\n",
    "    input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "    label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name=\"ctc\")([output, labels, input_length, label_length])\n",
    "\n",
    "    model = Model(input=[net_input, labels, input_length, label_length], output=[loss_out])\n",
    "    model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=optimizer, metrics=[])\n",
    "\n",
    "    test_func = K.function([net_input], [output])\n",
    "    \n",
    "    return model, test_func\n",
    "\n",
    "model, test_func = build_model(nb_feat=nb_feat, nb_class=nb_class, optimizer=optimizer)\n",
    "model.summary()\n",
    "\n",
    "# X, y, valid_idxs = get_sample(ids=None, take_all=True)\n",
    "# y = np.argmax(to_categorical(y, params), axis=1)\n",
    "# y = np.reshape(y, (y.shape[0], 1))\n",
    "# X, X_mask = pad_sequence_into_array(X, maxlen=78)\n",
    "# y, y_mask = pad_sequence_into_array(y, maxlen=1)\n",
    "# index_to_retain = np.sum(X_mask, axis=1, dtype=np.int32) > 5\n",
    "# X, X_mask = X[index_to_retain], X_mask[index_to_retain]\n",
    "# y, y_mask = y[index_to_retain], y_mask[index_to_retain]\n",
    "# idxs_train, idxs_test = train_test_split(range(X.shape[0]))\n",
    "# X_train, X_test = X[idxs_train], X[idxs_test]\n",
    "# X_train_mask, X_test_mask = X_mask[idxs_train], X_mask[idxs_test]\n",
    "# y_train, y_test = y[idxs_train], y[idxs_test]\n",
    "# y_train_mask, y_test_mask = y_mask[idxs_train], y_mask[idxs_test]\n",
    "# sess = tf.Session()\n",
    "\n",
    "# class_weights = np.unique(y, return_counts=True)[1]*1.\n",
    "# class_weights = np.sum(class_weights) / class_weights\n",
    "\n",
    "# sample_weight = np.zeros(y_train.shape[0])\n",
    "# for num, i in enumerate(y_train):\n",
    "#     sample_weight[num] = class_weights[i[0]]\n",
    "\n",
    "# ua_train = np.zeros(nb_epoch)\n",
    "# ua_test = np.zeros(nb_epoch)\n",
    "# wa_train = np.zeros(nb_epoch)\n",
    "# wa_test = np.zeros(nb_epoch)\n",
    "# loss_train = np.zeros(nb_epoch)\n",
    "# loss_test = np.zeros(nb_epoch)\n",
    "\n",
    "# last_test_loss = 100\n",
    "# for epoch in range(nb_epoch):\n",
    "#     epoch_time0 = time.time()\n",
    "    \n",
    "#     total_ctcloss = 0.0\n",
    "#     batches = range(0, X_train.shape[0], batch_size)\n",
    "#     shuffle = np.random.choice(batches, size=len(batches), replace=False)\n",
    "#     for num, i in enumerate(shuffle):\n",
    "#         inputs_train = {'the_input': X_train[i:i+batch_size],\n",
    "#                         'the_labels': y_train[i:i+batch_size],\n",
    "#                         'input_length': np.sum(X_train_mask[i:i+batch_size], axis=1, dtype=np.int32),\n",
    "#                         'label_length': np.squeeze(y_train_mask[i:i+batch_size]),\n",
    "#                        }\n",
    "#         outputs_train = {'ctc': np.zeros([inputs_train[\"the_labels\"].shape[0]])}\n",
    "\n",
    "#         ctcloss = model.train_on_batch(x=inputs_train, y=outputs_train, \n",
    "#                                        sample_weight=sample_weight[i:i+batch_size])\n",
    "\n",
    "#         total_ctcloss += ctcloss * inputs_train[\"the_input\"].shape[0] * 1.\n",
    "#     loss_train[epoch] = total_ctcloss / X_train.shape[0]\n",
    "\n",
    "#     inputs_train = {'the_input': X_train,\n",
    "#                     'the_labels': y_train,\n",
    "#                     'input_length': np.sum(X_train_mask, axis=1, dtype=np.int32),\n",
    "#                     'label_length': np.squeeze(y_train_mask),\n",
    "#                    }\n",
    "#     outputs_train = {'ctc': np.zeros([y_train.shape[0]])}\n",
    "#     preds = test_func([inputs_train[\"the_input\"]])[0]\n",
    "#     decode_function = K.ctc_decode(preds[:,2:,:], inputs_train[\"input_length\"]-2, greedy=False, top_paths=1)\n",
    "#     labellings = decode_function[0][0].eval(session=sess)\n",
    "#     if labellings.shape[1] == 0:\n",
    "#         ua_train[epoch] = 0.0\n",
    "#         wa_train[epoch] = 0.0\n",
    "#     else:\n",
    "#         ua_train[epoch] = unweighted_accuracy(y_train.ravel(), labellings.T[0].ravel())\n",
    "#         wa_train[epoch] = weighted_accuracy(y_train.ravel(), labellings.T[0].ravel())\n",
    "\n",
    "\n",
    "#     inputs_test = {'the_input': X_test,\n",
    "#                    'the_labels': y_test,\n",
    "#                    'input_length': np.sum(X_test_mask, axis=1, dtype=np.int32),\n",
    "#                    'label_length': np.squeeze(y_test_mask),\n",
    "#                   }\n",
    "#     outputs_test = {'ctc': np.zeros([y_test.shape[0]])}\n",
    "#     preds = test_func([inputs_test[\"the_input\"]])[0]\n",
    "#     decode_function = K.ctc_decode(preds[:,2:,:], inputs_test[\"input_length\"]-2, greedy=False, top_paths=1)\n",
    "#     labellings = decode_function[0][0].eval(session=sess)\n",
    "#     if labellings.shape[1] == 0:\n",
    "#         ua_test[epoch] = 0.0\n",
    "#         wa_test[epoch] = 0.0\n",
    "#     else:\n",
    "#         ua_test[epoch] = unweighted_accuracy(y_test.ravel(), labellings.T[0].ravel())\n",
    "#         wa_test[epoch] = weighted_accuracy(y_test.ravel(), labellings.T[0].ravel())\n",
    "#     loss_test[epoch] = np.mean(model.predict(inputs_test))\n",
    "#     epoch_time1 = time.time()\n",
    "\n",
    "#     print('epoch = %d, \\\n",
    "# WA Tr = %0.2f, UA Tr = %0.2f, WA Te = %0.2f, UA Te = %0.2f, CTC Tr = %0.2f, CTC Te = %0.2f, \\\n",
    "# time = %0.2fmins' % (epoch + 1, \n",
    "#                      wa_train[epoch], ua_train[epoch], \n",
    "#                      wa_test[epoch], ua_test[epoch], \n",
    "#                      loss_train[epoch], loss_test[epoch],\n",
    "#                      (epoch_time1-epoch_time0)/60))\n",
    "#     if loss_test[epoch]<last_test_loss:\n",
    "#         print('saving model....')\n",
    "#         model.save('ctc_emotion_model.h5')\n",
    "#         last_test_loss = loss_test[epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('ctc_emotion_model.h5',custom_objects={'<lambda>': lambda y_true, y_pred: y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_layer_model = Model(inputs = model.input,outputs=model.get_layer('time_distributed_2').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-89f823e68357>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m inputs_test2 = {'the_input': X_test[0].reshape((1,X_test[0].shape[0],X_test[0].shape[1])),\n\u001b[0m\u001b[0;32m      2\u001b[0m                    \u001b[1;34m'the_labels'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                    \u001b[1;34m'input_length'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_test_mask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                    \u001b[1;34m'label_length'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_test_mask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                   }\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "inputs_test2 = {'the_input': X_test[0].reshape((1,X_test[0].shape[0],X_test[0].shape[1])),\n",
    "                   'the_labels': y_test[0].reshape((1,y_test[0].shape[0])),\n",
    "                   'input_length': np.sum([X_test_mask[0]], axis=1, dtype=np.int32),\n",
    "                   'label_length': y_test_mask[0].reshape((1,)),\n",
    "                  }\n",
    "# inputs_test2['label_length'].shape\n",
    "pred = intermediate_layer_model.predict(inputs_test2)\n",
    "decode_function = K.ctc_decode(pred[:,2:,:], inputs_test2[\"input_length\"]-2, greedy=False, top_paths=1)\n",
    "labelling = decode_function[0][0].eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
