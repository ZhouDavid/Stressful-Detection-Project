{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python35\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "d:\\python35\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n",
      "d:\\python35\\lib\\site-packages\\ipykernel_launcher.py:53: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(activation=\"tanh\", units=64, return_sequences=True)`\n",
      "d:\\python35\\lib\\site-packages\\ipykernel_launcher.py:58: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(activation=\"tanh\", units=64, go_backwards=True, return_sequences=True)`\n",
      "d:\\python35\\lib\\site-packages\\ipykernel_launcher.py:60: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "d:\\python35\\lib\\site-packages\\ipykernel_launcher.py:64: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(activation=\"tanh\", units=64, return_sequences=True)`\n",
      "d:\\python35\\lib\\site-packages\\ipykernel_launcher.py:69: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(activation=\"tanh\", units=64, go_backwards=True, return_sequences=True)`\n",
      "d:\\python35\\lib\\site-packages\\ipykernel_launcher.py:71: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "d:\\python35\\lib\\site-packages\\ipykernel_launcher.py:81: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "the_input (InputLayer)          (None, 78, 34)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 78, 64)       25344       the_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 78, 64)       25344       the_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "merge_1 (Merge)                 (None, 78, 128)      0           lstm_1[0][0]                     \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 78, 64)       49408       merge_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   (None, 78, 64)       49408       merge_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "merge_2 (Merge)                 (None, 78, 128)      0           lstm_3[0][0]                     \n",
      "                                                                 lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 78, 512)      66048       merge_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 78, 5)        2565        time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "the_labels (InputLayer)         (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_length (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "label_length (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ctc (Lambda)                    (None, 1)            0           time_distributed_2[0][0]         \n",
      "                                                                 the_labels[0][0]                 \n",
      "                                                                 input_length[0][0]               \n",
      "                                                                 label_length[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 218,117\n",
      "Trainable params: 218,117\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.cross_validation import StratifiedKFold, KFold, train_test_split\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential, Model, model_from_json\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers import Merge\n",
    "from keras.layers import LSTM, Input, Lambda\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from utilities.utils import *\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "# %matplotlib inline\n",
    "\n",
    "# from IPython.display import clear_output\n",
    "batch_size = 64\n",
    "nb_feat = 34 # feature 向量的维度\n",
    "nb_class = 4 # 情绪分类数量\n",
    "nb_epoch = 100\n",
    "\n",
    "optimizer = 'Adadelta'\n",
    "\n",
    "params = Constants()\n",
    "params.path_to_data = \"C:\\\\Users\\\\SparcGuys\\\\Desktop\\\\IEMOCAP_full_release\\\\\"\n",
    "\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    # the 2 is critical here since the first couple outputs of the RNN\n",
    "    # tend to be garbage:\n",
    "    shift = 2\n",
    "    y_pred = y_pred[:, shift:, :]\n",
    "    input_length -= shift\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "def build_model(nb_feat, nb_class, optimizer='Adadelta'):\n",
    "    net_input = Input(name=\"the_input\", shape=(78, nb_feat))\n",
    "    forward_lstm1  = LSTM(output_dim=64, \n",
    "                          return_sequences=True, \n",
    "                          activation=\"tanh\"\n",
    "                         )(net_input)\n",
    "    backward_lstm1 = LSTM(output_dim=64, \n",
    "                          return_sequences=True, \n",
    "                          activation=\"tanh\",\n",
    "                          go_backwards=True\n",
    "                         )(net_input)\n",
    "    blstm_output1  = Merge(mode='concat')([forward_lstm1, backward_lstm1])\n",
    "\n",
    "    forward_lstm2  = LSTM(output_dim=64, \n",
    "                          return_sequences=True, \n",
    "                          activation=\"tanh\"\n",
    "                         )(blstm_output1)\n",
    "    backward_lstm2 = LSTM(output_dim=64, \n",
    "                          return_sequences=True, \n",
    "                          activation=\"tanh\",\n",
    "                          go_backwards=True\n",
    "                         )(blstm_output1)\n",
    "    blstm_output2  = Merge(mode='concat')([forward_lstm2, backward_lstm2])\n",
    "\n",
    "    hidden = TimeDistributed(Dense(512, activation='tanh'))(blstm_output2)\n",
    "    output = TimeDistributed(Dense(nb_class + 1, activation='softmax'))(hidden)\n",
    "\n",
    "    labels = Input(name='the_labels', shape=[1], dtype='float32')\n",
    "    input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "    label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name=\"ctc\")([output, labels, input_length, label_length])\n",
    "\n",
    "    model = Model(input=[net_input, labels, input_length, label_length], output=[loss_out])\n",
    "    model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=optimizer, metrics=[])\n",
    "\n",
    "    test_func = K.function([net_input], [output])\n",
    "    \n",
    "    return model, test_func\n",
    "\n",
    "model, test_func = build_model(nb_feat=nb_feat, nb_class=nb_class, optimizer=optimizer)\n",
    "model.summary()\n",
    "\n",
    "# X, y, valid_idxs = get_sample(ids=None, take_all=True)\n",
    "# y = np.argmax(to_categorical(y, params), axis=1)\n",
    "# y = np.reshape(y, (y.shape[0], 1))\n",
    "# X, X_mask = pad_sequence_into_array(X, maxlen=78)\n",
    "# y, y_mask = pad_sequence_into_array(y, maxlen=1)\n",
    "# index_to_retain = np.sum(X_mask, axis=1, dtype=np.int32) > 5\n",
    "# X, X_mask = X[index_to_retain], X_mask[index_to_retain]\n",
    "# y, y_mask = y[index_to_retain], y_mask[index_to_retain]\n",
    "# idxs_train, idxs_test = train_test_split(range(X.shape[0]))\n",
    "# X_train, X_test = X[idxs_train], X[idxs_test]\n",
    "# X_train_mask, X_test_mask = X_mask[idxs_train], X_mask[idxs_test]\n",
    "# y_train, y_test = y[idxs_train], y[idxs_test]\n",
    "# y_train_mask, y_test_mask = y_mask[idxs_train], y_mask[idxs_test]\n",
    "# sess = tf.Session()\n",
    "\n",
    "# class_weights = np.unique(y, return_counts=True)[1]*1.\n",
    "# class_weights = np.sum(class_weights) / class_weights\n",
    "\n",
    "# sample_weight = np.zeros(y_train.shape[0])\n",
    "# for num, i in enumerate(y_train):\n",
    "#     sample_weight[num] = class_weights[i[0]]\n",
    "\n",
    "# ua_train = np.zeros(nb_epoch)\n",
    "# ua_test = np.zeros(nb_epoch)\n",
    "# wa_train = np.zeros(nb_epoch)\n",
    "# wa_test = np.zeros(nb_epoch)\n",
    "# loss_train = np.zeros(nb_epoch)\n",
    "# loss_test = np.zeros(nb_epoch)\n",
    "\n",
    "# last_test_loss = 100\n",
    "# for epoch in range(nb_epoch):\n",
    "#     epoch_time0 = time.time()\n",
    "    \n",
    "#     total_ctcloss = 0.0\n",
    "#     batches = range(0, X_train.shape[0], batch_size)\n",
    "#     shuffle = np.random.choice(batches, size=len(batches), replace=False)\n",
    "#     for num, i in enumerate(shuffle):\n",
    "#         inputs_train = {'the_input': X_train[i:i+batch_size],\n",
    "#                         'the_labels': y_train[i:i+batch_size],\n",
    "#                         'input_length': np.sum(X_train_mask[i:i+batch_size], axis=1, dtype=np.int32),\n",
    "#                         'label_length': np.squeeze(y_train_mask[i:i+batch_size]),\n",
    "#                        }\n",
    "#         outputs_train = {'ctc': np.zeros([inputs_train[\"the_labels\"].shape[0]])}\n",
    "\n",
    "#         ctcloss = model.train_on_batch(x=inputs_train, y=outputs_train, \n",
    "#                                        sample_weight=sample_weight[i:i+batch_size])\n",
    "\n",
    "#         total_ctcloss += ctcloss * inputs_train[\"the_input\"].shape[0] * 1.\n",
    "#     loss_train[epoch] = total_ctcloss / X_train.shape[0]\n",
    "\n",
    "#     inputs_train = {'the_input': X_train,\n",
    "#                     'the_labels': y_train,\n",
    "#                     'input_length': np.sum(X_train_mask, axis=1, dtype=np.int32),\n",
    "#                     'label_length': np.squeeze(y_train_mask),\n",
    "#                    }\n",
    "#     outputs_train = {'ctc': np.zeros([y_train.shape[0]])}\n",
    "#     preds = test_func([inputs_train[\"the_input\"]])[0]\n",
    "#     decode_function = K.ctc_decode(preds[:,2:,:], inputs_train[\"input_length\"]-2, greedy=False, top_paths=1)\n",
    "#     labellings = decode_function[0][0].eval(session=sess)\n",
    "#     if labellings.shape[1] == 0:\n",
    "#         ua_train[epoch] = 0.0\n",
    "#         wa_train[epoch] = 0.0\n",
    "#     else:\n",
    "#         ua_train[epoch] = unweighted_accuracy(y_train.ravel(), labellings.T[0].ravel())\n",
    "#         wa_train[epoch] = weighted_accuracy(y_train.ravel(), labellings.T[0].ravel())\n",
    "\n",
    "\n",
    "#     inputs_test = {'the_input': X_test,\n",
    "#                    'the_labels': y_test,\n",
    "#                    'input_length': np.sum(X_test_mask, axis=1, dtype=np.int32),\n",
    "#                    'label_length': np.squeeze(y_test_mask),\n",
    "#                   }\n",
    "#     outputs_test = {'ctc': np.zeros([y_test.shape[0]])}\n",
    "#     preds = test_func([inputs_test[\"the_input\"]])[0]\n",
    "#     decode_function = K.ctc_decode(preds[:,2:,:], inputs_test[\"input_length\"]-2, greedy=False, top_paths=1)\n",
    "#     labellings = decode_function[0][0].eval(session=sess)\n",
    "#     if labellings.shape[1] == 0:\n",
    "#         ua_test[epoch] = 0.0\n",
    "#         wa_test[epoch] = 0.0\n",
    "#     else:\n",
    "#         ua_test[epoch] = unweighted_accuracy(y_test.ravel(), labellings.T[0].ravel())\n",
    "#         wa_test[epoch] = weighted_accuracy(y_test.ravel(), labellings.T[0].ravel())\n",
    "#     loss_test[epoch] = np.mean(model.predict(inputs_test))\n",
    "#     epoch_time1 = time.time()\n",
    "\n",
    "#     print('epoch = %d, \\\n",
    "# WA Tr = %0.2f, UA Tr = %0.2f, WA Te = %0.2f, UA Te = %0.2f, CTC Tr = %0.2f, CTC Te = %0.2f, \\\n",
    "# time = %0.2fmins' % (epoch + 1, \n",
    "#                      wa_train[epoch], ua_train[epoch], \n",
    "#                      wa_test[epoch], ua_test[epoch], \n",
    "#                      loss_train[epoch], loss_test[epoch],\n",
    "#                      (epoch_time1-epoch_time0)/60))\n",
    "#     if loss_test[epoch]<last_test_loss:\n",
    "#         print('saving model....')\n",
    "#         model.save('ctc_emotion_model.h5')\n",
    "#         last_test_loss = loss_test[epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python35\\lib\\site-packages\\keras\\engine\\topology.py:1269: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  return cls(**config)\n"
     ]
    }
   ],
   "source": [
    "model = load_model('ctc_emotion_model.h5',custom_objects={'<lambda>': lambda y_true, y_pred: y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_layer_model = Model(inputs = model.input,outputs=model.get_layer('time_distributed_2').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test2 = {'the_input': X_test[0].reshape((1,X_test[0].shape[0],X_test[0].shape[1])),\n",
    "                   'the_labels': y_test[0].reshape((1,y_test[0].shape[0])),\n",
    "                   'input_length': np.sum([X_test_mask[0]], axis=1, dtype=np.int32),\n",
    "                   'label_length': y_test_mask[0].reshape((1,)),\n",
    "                  }\n",
    "# inputs_test2['label_length'].shape\n",
    "pred = intermediate_layer_model.predict(inputs_test2)\n",
    "decode_function = K.ctc_decode(pred[:,2:,:], inputs_test2[\"input_length\"]-2, greedy=False, top_paths=1)\n",
    "labelling = decode_function[0][0].eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
